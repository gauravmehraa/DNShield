import tkinter as tk
from tkinter import messagebox, scrolledtext
from tkinter import ttk
import threading
import queue
import time
import pandas as pd
import numpy as np
import ast
import joblib
import re
from datetime import datetime
from tensorflow.keras.models import load_model
from scapy.all import sniff, DNS, DNSQR, DNSRR
from math import log2
from collections import Counter
from PIL import Image, ImageTk

# ---------------------------
# Global variables and thread communication
# ---------------------------
firewall_running = False
firewall_thread = None
message_queue = queue.Queue()
consecutive_threat_count = 0  # Counter for consecutive harmful predictions

# ---------------------------
# Load the saved model and preprocessing objects
# ---------------------------
model = load_model('models/model_batchsize64_sequence5.h5')
le_label = joblib.load('encoders/label_encoder.pkl')
le_tld = joblib.load('encoders/le_dns_top_level_domain.pkl')
le_sld = joblib.load('encoders/le_dns_second_level_domain.pkl')
scaler = joblib.load('encoders/scaler.pkl')

# ---------------------------
# Helper functions for feature extraction
# ---------------------------
def parse_list_safe(list_entry):
    if isinstance(list_entry, list):
        return list_entry
    elif isinstance(list_entry, str):
        try:
            return ast.literal_eval(list_entry)
        except (ValueError, SyntaxError):
            return []
    else:
        return []

def extract_vowels_consonants(dist):
    vowels = set('aeiou')
    consonants = set('bcdfghjklmnpqrstvwxyz')
    vowel_count = 0
    consonant_count = 0
    if isinstance(dist, str):
        try:
            dist = ast.literal_eval(dist)
        except (ValueError, SyntaxError):
            dist = {}
    if isinstance(dist, dict):
        for ch, cnt in dist.items():
            if ch in vowels:
                vowel_count += cnt
            elif ch in consonants:
                consonant_count += cnt
    return vowel_count, consonant_count

feature_order = [
    'dns_domain_name_length',
    'numerical_percentage',
    'character_entropy',
    'max_continuous_numeric_len',
    'max_continuous_alphabet_len',
    'vowels_consonant_ratio',
    'conv_freq_vowels_consonants',
    'packets_numbers',
    'receiving_packets_numbers',
    'sending_packets_numbers',
    'receiving_bytes',
    'sending_bytes',
    'distinct_ttl_values',
    'ttl_values_min',
    'ttl_values_max',
    'ttl_values_mean',
    'dns_top_level_domain_encoded',
    'dns_second_level_domain_encoded',
    'uni_gram_count',
    'bi_gram_count',
    'tri_gram_count',
    'query_resource_record_type_count',
    'ans_resource_record_type_count',
    'query_resource_record_class_count',
    'ans_resource_record_class_count',
    'vowel_count',
    'consonant_count'
]

# ---------------------------
# Buffer and sequence length for prediction
# ---------------------------
sequence_length = 5
event_buffer = []

def preprocess_event(event):
    try:
        _ = pd.to_datetime(event.get('timestamp'))
    except Exception:
        pass

    placeholder = 'unknown'
    tld = event.get('dns_top_level_domain', placeholder) or placeholder
    sld = event.get('dns_second_level_domain', placeholder) or placeholder
    if tld not in le_tld.classes_:
        tld = 'unknown'
    if sld not in le_sld.classes_:
        sld = 'unknown'
    tld_encoded = int(le_tld.transform([tld])[0])
    sld_encoded = int(le_sld.transform([sld])[0])
    
    uni_gram_list = parse_list_safe(event.get('uni_gram_domain_name', []))
    bi_gram_list = parse_list_safe(event.get('bi_gram_domain_name', []))
    tri_gram_list = parse_list_safe(event.get('tri_gram_domain_name', []))
    uni_gram_count = len(uni_gram_list)
    bi_gram_count = len(bi_gram_list)
    tri_gram_count = len(tri_gram_list)
    
    def count_unique(val):
        lst = parse_list_safe(val)
        return len(set(lst)) if lst else 0
    query_rr_type_count = count_unique(event.get('query_resource_record_type', []))
    ans_rr_type_count = count_unique(event.get('ans_resource_record_type', []))
    query_rr_class_count = count_unique(event.get('query_resource_record_class', []))
    ans_rr_class_count = count_unique(event.get('ans_resource_record_class', []))
    
    vowel_count, consonant_count = extract_vowels_consonants(event.get('character_distribution', {}))
    
    conv_freq = event.get('conv_freq_vowels_consonants', 0.0)
    
    features = {
        'dns_domain_name_length': event.get('dns_domain_name_length', 0),
        'numerical_percentage': event.get('numerical_percentage', 0.0),
        'character_entropy': event.get('character_entropy', 0.0),
        'max_continuous_numeric_len': event.get('max_continuous_numeric_len', 0),
        'max_continuous_alphabet_len': event.get('max_continuous_alphabet_len', 0),
        'packets_numbers': event.get('packets_numbers', 0),
        'receiving_packets_numbers': event.get('receiving_packets_numbers', 0),
        'sending_packets_numbers': event.get('sending_packets_numbers', 0),
        'receiving_bytes': event.get('receiving_bytes', 0),
        'sending_bytes': event.get('sending_bytes', 0),
        'distinct_ttl_values': event.get('distinct_ttl_values', 0),
        'ttl_values_min': event.get('ttl_values_min', -1),
        'ttl_values_max': event.get('ttl_values_max', -1),
        'ttl_values_mean': event.get('ttl_values_mean', -1.0),
        'uni_gram_count': uni_gram_count,
        'bi_gram_count': bi_gram_count,
        'tri_gram_count': tri_gram_count,
        'query_resource_record_type_count': query_rr_type_count,
        'ans_resource_record_type_count': ans_rr_type_count,
        'query_resource_record_class_count': query_rr_class_count,
        'ans_resource_record_class_count': ans_rr_class_count,
        'vowels_consonant_ratio': event.get('vowels_consonant_ratio', 0.0),
        'conv_freq_vowels_consonants': conv_freq,
        'vowel_count': vowel_count,
        'consonant_count': consonant_count,
        'dns_top_level_domain_encoded': tld_encoded,
        'dns_second_level_domain_encoded': sld_encoded
    }
    return features

def predict_dns_event(event):
    features = preprocess_event(event)
    df_event = pd.DataFrame([features], columns=feature_order)
    scaled_features = scaler.transform(df_event)
    event_buffer.append(scaled_features[0])
    while len(event_buffer) < sequence_length:
        event_buffer.insert(0, scaled_features[0])
    if len(event_buffer) > sequence_length:
        event_buffer.pop(0)
    sequence_input = np.array(event_buffer).reshape(1, sequence_length, -1)
    pred_probs = model.predict(sequence_input)
    pred_class = np.argmax(pred_probs, axis=1)[0]
    predicted_label = le_label.inverse_transform([pred_class])[0]
    return predicted_label, pred_probs

def process_packet(packet):
    global consecutive_threat_count
    if packet.haslayer(DNS):
        dns_layer = packet.getlayer(DNS)
        event_type = "Query" if dns_layer.qr == 0 else "Response"
        if packet.haslayer(DNSQR):
            query_name = packet[DNSQR].qname.decode('utf-8').strip('.')
        elif packet.haslayer(DNSRR):
            query_name = packet[DNSRR].rrname.decode('utf-8').strip('.')
        else:
            query_name = "unknown"
        
        event = {}
        event['timestamp'] = datetime.fromtimestamp(packet.time).strftime("%Y-%m-%d %H:%M:%S.%f")
        parts = query_name.split('.')
        if len(parts) >= 2:
            event['dns_top_level_domain'] = parts[-1]
            event['dns_second_level_domain'] = parts[-2]
        else:
            event['dns_top_level_domain'] = 'unknown'
            event['dns_second_level_domain'] = 'unknown'
        event['dns_domain_name_length'] = len(query_name)
        digits = sum(c.isdigit() for c in query_name)
        event['numerical_percentage'] = digits / len(query_name) if query_name else 0.0
        freq = {}
        for c in query_name:
            freq[c] = freq.get(c, 0) + 1
        entropy = -sum((count/len(query_name)) * log2(count/len(query_name)) for count in freq.values()) if query_name else 0.0
        event['character_entropy'] = entropy
        numeric_runs = re.findall(r'\d+', query_name)
        event['max_continuous_numeric_len'] = max((len(run) for run in numeric_runs), default=0)
        alpha_runs = re.findall(r'[a-zA-Z]+', query_name)
        event['max_continuous_alphabet_len'] = max((len(run) for run in alpha_runs), default=0)
        event['packets_numbers'] = 1
        event['receiving_packets_numbers'] = 1 if dns_layer.qr == 1 else 0
        event['sending_packets_numbers'] = 1 if dns_layer.qr == 0 else 0
        event['receiving_bytes'] = len(packet) if dns_layer.qr == 1 else 0
        event['sending_bytes'] = len(packet) if dns_layer.qr == 0 else 0
        if packet.haslayer(DNSRR):
            ttl = packet[DNSRR].ttl
            event['distinct_ttl_values'] = 1
            event['ttl_values_min'] = ttl
            event['ttl_values_max'] = ttl
            event['ttl_values_mean'] = float(ttl)
        else:
            event['distinct_ttl_values'] = 0
            event['ttl_values_min'] = -1
            event['ttl_values_max'] = -1
            event['ttl_values_mean'] = -1.0
        event['query_resource_record_type'] = []
        event['ans_resource_record_type'] = []
        event['query_resource_record_class'] = []
        event['ans_resource_record_class'] = []
        def create_ngrams(s, n):
            return [s[i:i+n] for i in range(len(s)-n+1)]
        event['uni_gram_domain_name'] = create_ngrams(query_name, 1)
        event['bi_gram_domain_name'] = create_ngrams(query_name, 2)
        event['tri_gram_domain_name'] = create_ngrams(query_name, 3)
        event['character_distribution'] = dict(Counter(query_name))
        vowels = set('aeiouAEIOU')
        consonants = set('bcdfghjklmnpqrstvwxyzBCDFGHJKLMNPQRSTVWXYZ')
        vowel_count = sum(1 for c in query_name if c in vowels)
        consonant_count = sum(1 for c in query_name if c in consonants)
        event['vowels_consonant_ratio'] = vowel_count / consonant_count if consonant_count > 0 else 0.0

        label, probs = predict_dns_event(event)
        log_message = f"[{event['timestamp'].split('.')[0]}] [{label} {event_type}]: {query_name}"
        message_queue.put(('log', log_message))
        
        if label.lower() in ['malware', 'phishing', 'spam']:
            consecutive_threat_count += 1
        else:
            consecutive_threat_count = 0
        if consecutive_threat_count >= 3:
            message_queue.put(('alert', "Warning: Detected potential harmful activity more than 2/3 times in a row!"))
            consecutive_threat_count = 0

def run_firewall():
    while firewall_running:
        sniff(filter="udp port 53", prn=process_packet, store=0, timeout=1)

# ---------------------------
# Enhanced Tkinter UI using ttk for a modern design
# ---------------------------
class FirewallUI(tk.Tk):
    def __init__(self):
        super().__init__()
        self.title("DNShield")
        self.geometry("750x700")
        self.iconbitmap("icons/icon.ico")
        icon = Image.open('icons/icon.png')
        photo = ImageTk.PhotoImage(icon)
        self.wm_iconphoto(False, photo)
        self.configure(bg="#f0f0f0")
        
        # Store all logs for filtering
        self.all_logs = []
        
        # Configure ttk style for modern look
        style = ttk.Style(self)
        style.theme_use('clam')
        style.configure('TButton', font=('Segoe UI', 10, 'bold'), padding=6)
        style.configure('Header.TLabel', font=('Segoe UI', 18, 'bold'), background="#f0f0f0", foreground="#333")
        style.configure('SubHeader.TLabel', font=('Segoe UI', 12), background="#f0f0f0", foreground="#666")
        
        # Header frame with title
        header_frame = ttk.Frame(self, padding=(20, 10))
        header_frame.pack(fill='x')
        header_label = ttk.Label(header_frame, text="DNShield Control Panel", style='Header.TLabel')
        header_label.pack(side='left', anchor='center')
        
        # Filter frame
        filter_frame = ttk.Frame(self, padding=(20, 5))
        filter_frame.pack(fill='x')
        ttk.Label(filter_frame, text="Filter Logs:", font=('Segoe UI', 10)).pack(side='left')
        self.filter_var = tk.StringVar()
        self.filter_combobox = ttk.Combobox(filter_frame, textvariable=self.filter_var,
                                            values=["All", "Benign", "Malware", "Phishing", "Spam"],
                                            state="readonly", width=12)
        self.filter_combobox.current(0)
        self.filter_combobox.pack(side='left', padx=10)
        self.filter_combobox.bind("<<ComboboxSelected>>", self.update_log_view)
        
        # Stats frame: Display counts and percentages
        stats_frame = ttk.Frame(self, padding=(20, 5))
        stats_frame.pack(fill='x')
        self.stats_label = ttk.Label(stats_frame, text="Stats: ", font=('Segoe UI', 10))
        self.stats_label.pack(side='left')
        
        # Main content frame
        content_frame = ttk.Frame(self, padding=(20, 10))
        content_frame.pack(expand=True, fill='both')
        
        # Log frame with a label and a scrolled text widget
        log_frame = ttk.LabelFrame(content_frame, text="DNS Logs", padding=(10, 10))
        log_frame.pack(expand=True, fill='both', pady=(0,10))
        self.log_widget = scrolledtext.ScrolledText(log_frame, wrap=tk.WORD, font=('Segoe UI', 10), state='disabled', background="#ffffff")
        self.log_widget.pack(expand=True, fill='both')
        
        # Configure text tags for styling logs based on prediction (original spacing)
        self.log_widget.tag_configure("benign", foreground="#008000", font=("Segoe UI", 10))
        self.log_widget.tag_configure("malware", foreground="#FF0000", font=("Segoe UI", 10))
        self.log_widget.tag_configure("phishing", foreground="#FFA500", font=("Segoe UI", 10))
        self.log_widget.tag_configure("spam", foreground="#FFD700", font=("Segoe UI", 10))
        self.log_widget.tag_configure("other", foreground="#000000", font=("Segoe UI", 10))
        
        # Button frame
        button_frame = ttk.Frame(content_frame)
        button_frame.pack(pady=10)
        
        # Load icons from external image files and resize them using Pillow
        start_img = Image.open("icons/start_icon.png")
        start_img = start_img.resize((20, 20))
        self.start_icon = ImageTk.PhotoImage(start_img)
        stop_img = Image.open("icons/stop_icon.png")
        stop_img = stop_img.resize((20, 20))
        self.stop_icon = ImageTk.PhotoImage(stop_img)
        delete_img = Image.open("icons/delete_icon.png")
        delete_img = delete_img.resize((20, 20))
        self.delete_icon = ImageTk.PhotoImage(delete_img)
        
        self.start_button = ttk.Button(button_frame, text=" Start Firewall", command=self.start_firewall,
                                       image=self.start_icon, compound="left")
        self.start_button.pack(side='left', padx=10)
        self.stop_button = ttk.Button(button_frame, text=" Stop Firewall", command=self.stop_firewall,
                                      image=self.stop_icon, compound="left", state='disabled')
        self.stop_button.pack(side='left', padx=10)
        self.clear_button = ttk.Button(button_frame, text=" Clear Logs", command=self.clear_logs,
                                       image=self.delete_icon, compound="left")
        self.clear_button.pack(side='left', padx=10)
        
        # Status bar frame with colored indicator and text
        status_frame = ttk.Frame(self, relief='sunken', padding=5)
        status_frame.pack(fill='x', side='bottom')
        self.status_indicator = ttk.Label(status_frame, text="â—", font=('Segoe UI', 12, 'bold'))
        self.status_indicator.pack(side='left')
        self.status_var = tk.StringVar()
        self.status_var.set(" Status: Idle")
        self.status_label = ttk.Label(status_frame, textvariable=self.status_var, anchor='w')
        self.status_label.pack(side='left', padx=5)
        self.update_status_indicator("idle")
        
        # Start polling the message queue for logs and alerts
        self.poll_queue()
    
    def update_status_indicator(self, status):
        color = {"running": "green", "stopped": "red", "alert": "yellow", "idle": "gray"}.get(status, "gray")
        self.status_indicator.configure(foreground=color)
    
    def parse_prediction(self, message):
        if "-->" in message:
            pred = message.split("-->")[-1].strip().lower()
            if pred not in ["malware", "phishing", "spam"]:
                return "benign"
            return pred
        return "other"
    
    def update_stats(self):
        total = len(self.all_logs)
        benign = sum(1 for log in self.all_logs if log["prediction"] == "benign")
        malware = sum(1 for log in self.all_logs if log["prediction"] == "malware")
        phishing = sum(1 for log in self.all_logs if log["prediction"] == "phishing")
        spam = sum(1 for log in self.all_logs if log["prediction"] == "spam")
        benign_pct = (benign/total*100) if total else 0
        malware_pct = (malware/total*100) if total else 0
        phishing_pct = (phishing/total*100) if total else 0
        spam_pct = (spam/total*100) if total else 0
        text = (f"Total Logs: {total}  |  Benign: {benign} ({benign_pct:.1f}%)  |  "
                f"Malware: {malware} ({malware_pct:.1f}%)  |  Phishing: {phishing} ({phishing_pct:.1f}%)  |  "
                f"Spam: {spam} ({spam_pct:.1f}%)")
        self.stats_label.config(text=text)
    
    def log(self, message):
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        full_message = f"{message}"
        pred_type = self.parse_prediction(full_message)
        self.all_logs.append({"timestamp": timestamp, "prediction": pred_type, "message": full_message})
        self.update_stats()
        self.update_log_view()
    
    def update_log_view(self, event=None):
        current_filter = self.filter_var.get().lower()
        self.log_widget.configure(state='normal')
        self.log_widget.delete("1.0", tk.END)
        for entry in self.all_logs:
            # Always show all logs regardless of filter (or adjust if you want filtering)
            if current_filter == "all" or entry["prediction"] == current_filter:
                self.log_widget.insert(tk.END, entry["message"] + "\n", entry["prediction"])
        self.log_widget.configure(state='disabled')
        self.log_widget.see(tk.END)
    
    def clear_logs(self):
        self.all_logs.clear()
        self.log_widget.configure(state='normal')
        self.log_widget.delete("1.0", tk.END)
        self.log_widget.configure(state='disabled')
        self.update_stats()
    
    def poll_queue(self):
        while True:
            try:
                msg_type, content = message_queue.get_nowait()
            except queue.Empty:
                break
            if msg_type == 'log':
                self.log(content)
            elif msg_type == 'alert':
                messagebox.showwarning("Alert", content)
                self.status_var.set(" Status: Alert triggered!")
                self.update_status_indicator("alert")
        self.after(100, self.poll_queue)
    
    def start_firewall(self):
        global firewall_running, firewall_thread
        if not firewall_running:
            firewall_running = True
            firewall_thread = threading.Thread(target=run_firewall, daemon=True)
            firewall_thread.start()
            self.start_button.config(state='disabled')
            self.stop_button.config(state='normal')
            self.status_var.set(" Status: Running")
            self.update_status_indicator("running")
            self.log("Firewall started.")
            self.log("")
    
    def stop_firewall(self):
        global firewall_running, firewall_thread
        if firewall_running:
            firewall_running = False
            if firewall_thread:
                firewall_thread.join(timeout=2)
            self.start_button.config(state='normal')
            self.stop_button.config(state='disabled')
            self.status_var.set(" Status: Stopped")
            self.update_status_indicator("stopped")
            self.log("Firewall stopped.")
            self.log("")

if __name__ == '__main__':
    app = FirewallUI()
    app.mainloop()
